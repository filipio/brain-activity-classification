{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from nilearn.signal import clean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import EfficientFCParameters\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../dataset\"\n",
    "EXTRACTED_ZIP_DIR = f\"{DATASET_DIR}/AOMIC\"\n",
    "TS_DIR = f\"{EXTRACTED_ZIP_DIR}/TS\"\n",
    "NOISE_DIR = f\"{EXTRACTED_ZIP_DIR}/Noise\"\n",
    "DATASET_FILE_SUFFIX = \"_acq-seq_desc-confounds_regressors_6_motion_and_derivs.txt\"\n",
    "LABELS_DICT = {\n",
    "    \"task-restingstate\": 0,\n",
    "    \"task-stopsignal\": 1,\n",
    "    \"task-workingmemory\": 2,\n",
    "    \"task-emomatching\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    zip_file_path = f\"{DATASET_DIR}/AOMIC.zip\"\n",
    "    if not os.path.exists(EXTRACTED_ZIP_DIR):\n",
    "        print(\"Extracting dataset...\")\n",
    "        os.system(f\"unzip {zip_file_path} -d {EXTRACTED_ZIP_DIR}\")\n",
    "\n",
    "    dataset = []\n",
    "    labels = []\n",
    "\n",
    "    data_files_paths = [i for i in glob.glob(f\"{TS_DIR}/sub-*.txt\")]\n",
    "    data_files_paths.sort()\n",
    "    data_files_names = [i.split(\"/\")[-1] for i in data_files_paths]\n",
    "\n",
    "    for data_file_path, data_file_name in zip(data_files_paths, data_files_names):\n",
    "        # load dataset element\n",
    "        data = np.loadtxt(data_file_path)\n",
    "\n",
    "        file_name_parts = data_file_name.split(\"_\")\n",
    "        data_id = \"_\".join(file_name_parts[:2])\n",
    "\n",
    "        # clean the element (denoise, detrend, standardize)\n",
    "        noise = np.loadtxt(f\"{NOISE_DIR}/{data_id}{DATASET_FILE_SUFFIX}\")\n",
    "        cleaned_data = clean(data, confounds=noise, standardize=True, detrend=True)\n",
    "        dataset.append(cleaned_data)\n",
    "\n",
    "        # get label\n",
    "        label_key = file_name_parts[1]\n",
    "        labels.append(LABELS_DICT[label_key])\n",
    "\n",
    "    # make all elements of the dataset the same length (some time series are longer than others)\n",
    "    shortest_data_len = min([len(item) for item in dataset])\n",
    "    dataset = [item[:shortest_data_len] for item in dataset]\n",
    "\n",
    "    return np.array(dataset), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, labels = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# element x time x features\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(dataset, labels):\n",
    "    return train_test_split(dataset, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = split(dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(dataset):\n",
    "  ids = np.array([[id_value] * dataset.shape[1] for id_value in range(dataset.shape[0])])\n",
    "  ids = ids.reshape(-1)\n",
    "\n",
    "  df_values = dataset.reshape(-1, dataset.shape[2])\n",
    "  df = pd.DataFrame(df_values, columns=[f\"region{i}\" for i in range(df_values.shape[1])])\n",
    "  df[\"ids\"] = ids\n",
    "\n",
    "  # make ids the first column\n",
    "  df = df[[\"ids\"] + [c for c in df if c not in [\"ids\"]]]\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = create_dataframe(x_train)\n",
    "df_test = create_dataframe(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(df):\n",
    "  return extract_features(\n",
    "      df[:],\n",
    "      column_id=\"ids\",\n",
    "      default_fc_parameters=EfficientFCParameters(),\n",
    "      column_value=\"region0\", # for now only 1 region is used, to make\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = calculate_features(df_train)\n",
    "test_features = calculate_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed to make lightgbm work\n",
    "train_features.columns = [i for i in range(train_features.shape[1])]\n",
    "test_features.columns = [i for i in range(test_features.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = lgb.LGBMClassifier()\n",
    "classifier.fit(train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LightGBM Model accuracy score: {0:0.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_test, y_pred):\n",
    "  cm = confusion_matrix(y_test, y_pred).astype(np.float64)\n",
    "\n",
    "  for i in range(cm.shape[0]):\n",
    "      cm[i, :] /= np.sum(cm[i, :])\n",
    "\n",
    "  cm_matrix = pd.DataFrame(data=cm)\n",
    "  label_names = [key.split(\"-\")[1] for key in LABELS_DICT.keys()]\n",
    "  cm_matrix[\"types\"] = np.array(label_names)\n",
    "\n",
    "  cm_matrix.set_index(\"types\", inplace=True)\n",
    "  cm_matrix.columns = label_names\n",
    "\n",
    "  return cm_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_matrix = create_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm_matrix):\n",
    "  plt.figure(figsize=(7, 5))\n",
    "  sns.heatmap(\n",
    "      cm_matrix,\n",
    "      annot=True,\n",
    "      fmt=\".3f\",\n",
    "      square=True,\n",
    "      cbar=False,\n",
    "      cmap=\"Blues\",\n",
    "      linewidths=3,\n",
    "      vmin=0,\n",
    "      vmax=1,\n",
    "  )\n",
    "  plt.xlabel(\"Predicted label\", labelpad=16)\n",
    "  plt.ylabel(\"True label\", labelpad=12)\n",
    "  plt.tick_params(axis=\"y\", rotation=0)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
